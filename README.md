# Web Scraper and Knowledge Graph Generator

This project provides a Python script to scrape textual content from a given URL and then uses the OpenAI API to convert this text into a structured knowledge graph in JSON format.

## Features

- Scrapes main textual content (headings, paragraphs, lists, links) from a webpage.
- Saves the raw scraped text to `content.txt`.
- Sends the text to OpenAI's ChatGPT to extract entities and relationships.
- Outputs a knowledge graph as a JSON array, with each object containing:
    - `head`: The source entity.
    - `head_type`: Category/type of the source entity.
    - `relation`: The relationship between entities.
    - `tail`: The target entity.
    - `tail_type`: Category/type of the target entity.
- Saves the generated knowledge graph to `knowledge_graph.json`.

## Setup

1.  **Clone the repository (if you haven't already):**
    ```bash
    git clone <repository_url>
    cd <repository_directory>
    ```

2.  **Create and activate a virtual environment (recommended):**
    ```bash
    python -m venv venv
    ```
    *   On macOS and Linux:
        ```bash
        source venv/bin/activate
        ```
    *   On Windows:
        ```bash
        venv\Scripts\activate
        ```

3.  **Install dependencies:**
    ```bash
    pip install -r requirements.txt
    ```

4.  **Set up your OpenAI API Key:**
    The script requires an OpenAI API key to generate the knowledge graph. You need to set this key as an environment variable named `OPENAI_API_KEY`.

    *   On macOS and Linux:
        ```bash
        export OPENAI_API_KEY="your_actual_api_key_here"
        ```
        (You can add this line to your `.bashrc` or `.zshrc` for persistence)

    *   On Windows (Command Prompt):
        ```bash
        set OPENAI_API_KEY="your_actual_api_key_here"
        ```
    *   On Windows (PowerShell):
        ```bash
        $env:OPENAI_API_KEY="your_actual_api_key_here"
        ```
        (For persistent storage on Windows, search for "environment variables" in system settings.)

    **Note:** If the `OPENAI_API_KEY` is not set, the script will only perform web scraping and save the raw text to `content.txt`. Knowledge graph generation will be skipped.

## Running the Script

To run the script, use `main.py` with the URL of the website you want to process:

```bash
python main.py <URL_OF_WEBSITE>
```

**Example:**

```bash
python main.py https://en.wikipedia.org/wiki/Artificial_intelligence
```

## Output

The script will produce the following files in the project's root directory:

-   **`content.txt`**: Contains the raw, unstructured text scraped from the provided URL.
-   **`knowledge_graph.json`**: Contains the structured knowledge graph in JSON format, generated by the OpenAI API. This file is only created if the `OPENAI_API_KEY` was correctly set up and the API call was successful.

The `knowledge_graph.json` file will contain a JSON array of objects, where each object follows this structure:

```json
[
  {
    "head": "Example Entity 1",
    "head_type": "Type A",
    "relation": "is_related_to",
    "tail": "Example Entity 2",
    "tail_type": "Type B"
  },
  // ... more objects
]
```
